<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="ClimODE">
  <meta property="og:title" content="ClimODE: Climate and Weather Forecasting With Physics-informed Neural ODEs"/>
  <meta property="og:description" content="We introduce a novel climate modeling approach, inspired by physics, using ODEs that capture underlying inductive biases and allow for uncertainty quantification in predictions"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="neural ODE, time-series forecasting, climate prediction, physics-informed ML">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ClimODE</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ClimODE: Climate and Weather Forecasting With Physics-informed Neural ODEs</h1>
            <div class="is-size-5 publication-authors">
              <h6 style="font-size:30px;"><span style="color: #ff0000">Oral (Top 1%)</span>, ICLR 2024 </h6>
          
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yoverma.github.io/yoerma.github.io/" target="_blank">Yogesh Verma</a>,</span>
                <span class="author-block">
                  <a href="https://users.aalto.fi/~heinom10/" target="_blank">Markus Heinonen</a>,</span>
                  <span class="author-block">
                    <a href="https://www.mit.edu/~vgarg/" target="_blank">Vikas Garg</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Aalto University, Finland & YaiYai Ltd <br></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                   <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> --> 

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Aalto-QuML/ClimODE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" width="100%" id="tree" autoplay controls muted loop height="140%">
        <!-- Your video here -->
        <source src="static/videos/Slowed_video_combined_comp1.mp4"
        type="video/mp4" width="68">
      </video>
      <h2 class="subtitle has-text-justified">
        <b>We model climate/weather as a spatiotemporal process using the concept of advection.</b> This provides a <font color="red"> strong physical prior </font>  to modeling the spatiotemporal dynamics. In order to model the external sources and provide uncertainty quantification, we add a <font color="orange"> Gaussian emission model </font>, which models the day-night cycle and provides uncertainty quantification in the predictions. The video shows the predictions of the ClimODE model for various observables.  
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Climate and weather prediction traditionally relies on complex numerical simulations of atmospheric physics. Deep learning approaches, such as transformers, have recently challenged the simulation paradigm with complex network forecasts. However, <b> they often act as data-driven black-box models that neglect the underlying physics and lack uncertainty quantification</b>. We address these limitations with <font color="blue"> ClimODE, a spatiotemporal continuous-time process that implements a key principle of advection from statistical mechanics </font>, namely, weather changes due to a spatial movement of quantities over time. <font color="brown"> ClimODE models precise weather evolution with value-conserving dynamics, learning global weather transport as a neural flow, which also enables estimating the uncertainty in predictions </font>. Our approach outperforms existing data-driven methods in global and regional forecasting with an order of magnitude smaller parameterization, establishing a new state of the art.
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Overview</h2>

        <div class="tile is-ancestor is-centered">

          <div class="tile is-parent">
            <a href="#method-overview" class="tile is-child box">
              <p class="title is-4">Method</p>
              <p>
                How do we model weather/climate via advection?
              </p>
            </a>
          </div>

          <div class="tile is-parent">
            <a href="#visualizations" class="tile is-child box">
              <p class="title is-4">Visualizations</p>
              <p>
                Explore visualizations of how ClimODE models the global weather/climate.
              </p>
            </a>
          </div>
          

          <div class="tile is-parent">
            <a href="#results" class="tile is-child box">
              <p class="title is-4">Training Results</p>
              <p>
                Results of ClimODE in various weather forecasting tasks.
              </p>
            </a>
          </div>


          <div class="tile is-parent">
            <a href="#ablations" class="tile is-child box">
              <p class="title is-4">Ablations</p>
              <p>
                Ablations and Interpretability of Predictions
              </p>
            </a>
          </div>

          
        </div>

      </div>
    </div>

    
  </div>
</section>
<!-- End paper abstract -->




<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column is-full-width">
          <h2 class="title is-3" id="method-overview">Method Overview</h2>

          <div class="hero-body">
            <div class="field has-addons is-pulled-right" id="play-controls" title="Hint: Right click the video and choose 'Show All Controls' to enable more fine-grained video controls.">
              <p class="control">
                <button class="button is-small is-rounded" onclick="playPauseVideo('method')">
                  <span class="icon is-small">
                    &nbsp;<svg class="svg-inline--fa fa-play fa-w-14" aria-hidden="true" focusable="false" data-prefix="fa" data-icon="play" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M424.4 214.7L72.4 6.6C43.8-10.3 0 6.1 0 47.9V464c0 37.5 40.7 60.1 72.4 41.3l352-208c31.4-18.5 31.5-64.1 0-82.6z"></path></svg><!-- <i class="fa fa-play"></i> Font Awesome fontawesome.com -->&nbsp;<svg class="svg-inline--fa fa-pause fa-w-14" aria-hidden="true" focusable="false" data-prefix="fa" data-icon="pause" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M144 479H48c-26.5 0-48-21.5-48-48V79c0-26.5 21.5-48 48-48h96c26.5 0 48 21.5 48 48v352c0 26.5-21.5 48-48 48zm304-48V79c0-26.5-21.5-48-48-48h-96c-26.5 0-48 21.5-48 48v352c0 26.5 21.5 48 48 48h96c26.5 0 48-21.5 48-48z"></path></svg><!-- <i class="fa fa-pause"></i> Font Awesome fontawesome.com -->&nbsp;
                  </span>
                </button>
              </p>
              <p class="control">
                <button class="button is-small is-rounded" onclick="restartVideo('method')">
                  <span class="icon is-small">
                    <svg class="svg-inline--fa fa-redo fa-w-16" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="redo" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M500.33 0h-47.41a12 12 0 0 0-12 12.57l4 82.76A247.42 247.42 0 0 0 256 8C119.34 8 7.9 119.53 8 256.19 8.1 393.07 119.1 504 256 504a247.1 247.1 0 0 0 166.18-63.91 12 12 0 0 0 .48-17.43l-34-34a12 12 0 0 0-16.38-.55A176 176 0 1 1 402.1 157.8l-101.53-4.87a12 12 0 0 0-12.57 12v47.41a12 12 0 0 0 12 12h200.33a12 12 0 0 0 12-12V12a12 12 0 0 0-12-12z"></path></svg><!-- <i class="fas fa-redo"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Restart animation</span>
                </button>
              </p>
            </div>
          </div>
          <div class="hero-body has-text-centered">
            <video id="method" height="100%" width="80%" preload="metadata" title="Hint: Right click the video and choose 'Show All Controls' to enable more fine-grained video controls.">
              <source src="https://storage.googleapis.com/adversarial-prompts/images/diff-dataset-method.mp4#t=0.1" type="video/mp4">
            </video>
            <h3 class="subtitle has-text-justified">
              <b>Our method consists of two feedback mechanisms.</b>
              Our first model-aware feedback mechanism finds <span class="ap-text">Adversarial Prompts</span> that produce training exampples by maximizing the supervised loss.
              Our second target distribution-aware feedback mechanism finds prompts that produce training examples similar to a target distribution.
              We use CLIP to measure the similarity between the generated images and the target distribution.
              Combining these two feedback mechanisms results in <span class="gap-text">Guided Adversarial Prompts</span>.
            </h3>

          </div>
  
          <div>
            <div class="content has-text-justified">
              <p>
              </p>
            </div>
            
            <!-- <h3 class="title is-4 ap-text">Adversarial Prompts</h3> -->
            
            <h2 class="title is-4 has-text-justified">Generating aligned image-label examples</h2>
            <div class="content has-text-justified">
              <p>
                We need aligned examples for supervised training, where an aligned example is an RGB image and its label. 
                We employ the follow two approaches.
                <!-- We employ the following two approaches to condition the generative model g on the label y and sample-aligned training examples (x ̃, y).  -->
                <!-- For the depth estimation task, we use the ControlNet model <a href="https://arxiv.org/abs/2302.05543">(Zhang L. et al.)</a> with depth conditioning. We use the depth maps from the training dataset. ControlNet then generates an RGB image conditioned on the given depth map. -->
                <!-- which extends the conditioning mechanisms of the Stable Diffusion to accept various spatial modalities, e.g., depth, segmentation masks, or edges.  -->
                <!-- Specifically, we use ControlNet v1.0 with depth conditioning1.  -->
                <!-- For semantic classification tasks, we utilize the foreground object masks and use an in-painting technique proposed by <a href="https://arxiv.org/abs/2201.09865">Lugmayr A. et al.</a> that preserves the masked region throughout the denoising process, essentially keeping it intact.  -->
                <!-- These mechanisms provide us with a generative model conditioned both on a text prompt and label.  -->
                <!-- We denote the resulting distribution modeled by this generative model as g(y, c). -->
              </p>
            </div>

            <div class="columns is-centered is-vcentered">
              <div class="column is-5 has-text-centered">
                <img src="https://storage.googleapis.com/adversarial-prompts/images/aligned-depth.png" alt="Agreement Score" class="img-center">
                <p class="has-text-justified gray">
                  <em style="color: gray;">
                    For the depth estimation task, we use the ControlNet model <a href="https://arxiv.org/abs/2302.05543">(Zhang L. et al.)</a> with depth conditioning. We use the depth maps from the training dataset. ControlNet then generates an RGB image conditioned on the given depth map.
                  </em>
                </p>
              </div>
              <div class="column is-1"></div>
              <div class="column is-5 has-text-centered">
                <img src="https://storage.googleapis.com/adversarial-prompts/images/aligned-classification.png" alt="Agreement Score" class="img-center">
                <p class="has-text-justified gray">
                  <em style="color: gray;">
                    For semantic classification tasks, we utilize the foreground object masks and use an in-painting technique proposed by <a href="https://arxiv.org/abs/2201.09865">Lugmayr A. et al.</a> that preserves the masked region throughout the denoising process, essentially keeping it intact. 
                  </em>
                </p>
              </div>
            </div>

            <h2 class="title is-4 has-text-justified">Optimization Trajectory</h2>
            <div class="content has-text-justified">
              <p>
                Below we demonstrate how <span class="ap-text">Adversarial Prompts</span> evolve over optimization steps for a model trained on the <a href="https://github.com/StanfordVL/taskonomy">Taskonomy dataset</a> for depth estimation task.
                Note how further optimization steps destroy some of the details resulting in generations less faithful to the depth map.
                To avoid training on such examples, we apply early stopping and SDEdit <a href="https://arxiv.org/abs/2108.01073">(Meng C. et al.)</a> image-to-image conditioning to generate training examples that are more faithful to the original label (see the paper for more details).
              </p>
            </div>


            <div class="bboxprobing-panel">
              <div class="columns is-mobile">
              <div class="column is-1 has-text-centered"></div>
              <div class="column is-3 has-text-centered">
                <div id="depth-iter-depth" class="rgb-image"><img src="https://storage.googleapis.com/adversarial-prompts/images/depth-data/gen-vs-iter/0/label/0.webp"></div>
                <h2 class="subtitle">Depth Map</h2>
              </div>
              <div class="column is-3 has-text-centered">
                <div id="depth-iter-orig-rgb" class="rgb-image"><img src="https://storage.googleapis.com/adversarial-prompts/images/depth-data/gen-vs-iter/0/original/0.webp"></div>
                <h2 class="subtitle">Original RGB</h2>
              </div>
              <div class="column is-1 has-text-centered"></div>
              <div class="column is-3 has-text-centered">
                <div id="depth-iter-generated" class="ap-image"><img src="https://storage.googleapis.com/adversarial-prompts/images/depth-data/gen-vs-iter/0/generated/0.webp"></div>
                  <h2 class="subtitle">Generated RGB<p class="ap-text"><em>(Adversarial Prompt)</em></p></h2>
                </div>
              </div>
  
              <div class="columns is-centered is-mobile is-vcentered">
                <!-- <div class="column is-1 has-text-centered"></div> -->
                <div class="column is-6 has-text-centered">
                  <input class="slider is-fullwidth is-large is-info has-output" id="depth-iter-slider" step="1" min="0" max="24" value="0" type="range">
                      
                  <br>
                  <button class="button" id="prev-button" onclick="prevDepthIterImage()">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-arrow-left fa-w-14" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="arrow-left" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M257.5 445.1l-22.2 22.2c-9.4 9.4-24.6 9.4-33.9 0L7 273c-9.4-9.4-9.4-24.6 0-33.9L201.4 44.7c9.4-9.4 24.6-9.4 33.9 0l22.2 22.2c9.5 9.5 9.3 25-.4 34.3L136.6 216H424c13.3 0 24 10.7 24 24v32c0 13.3-10.7 24-24 24H136.6l120.5 114.8c9.8 9.3 10 24.8.4 34.3z"></path></svg><!-- <i class="fas fa-arrow-left"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>Prev.</span>
                  </button>
                  <button class="button" id="next-button" onclick="nextDepthIterImage()">
                  <span>Next</span>
                  <span class="icon">
                      <svg class="svg-inline--fa fa-arrow-right fa-w-14" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="arrow-right" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"></path></svg><!-- <i class="fas fa-arrow-right"></i> Font Awesome fontawesome.com -->
                  </span>
                  </button>
                </div>
                <!-- <div class="column is-1 has-text-centered"></div> -->
              </div>
    
              <p style="text-align:center"><i>
                Hint: Drag the slider to change the adversarial optimization step.
                Use the buttons to explore different images.
              </i></p>
              <br>
            </div>
    

            <!-- <h3 class="title is-4">Guided Prompts</h3>

            <div class="content has-text-justified">
              <p>
                
              </p>
            </div> -->

            <br>

            <!-- <h3 class="title is-4 gap-text">Guided Adversarial Prompts</h3>

            <div class="content has-text-justified">
              <p>
                
              </p>
            </div> -->

          </div>

          <br>
        
          <h2 class="title is-3" id="results">Results</h2>

            <div class="content has-text-justified">
              We now show the ClimODE's forecasting capabilities by predicting the future state based on the initial state  for various lead times, focusing on key meteorological variables
            </div>

          <h3 class="title is-4">Global Forecasting</h3>
         
          <div class="columns is-centered is-vcentered">

            <div class="content has-text-justified">
              We assess ClimODE's performance in global forecasting, encompassing the prediction of crucial meteorological variables described above. It demonstrates <font color="red"> ClimODE's superior performance across all metrics and variables </font>  over other neural baselines, while falling short against the gold-standard IFS, as expected. These findings indicate the <font color="orange"> effectiveness of incorporating an underlying physical framework</font> for climate or weather modeling.
              <p align="center">
                  <img src="https://raw.githubusercontent.com/yogeshverma1998/ClimODE/master/static/images/global_forecast_updated.png" />
              </p>
              
            </div>
           </div> 
            <!-- <div class="column is-0.1"></div> -->

          <h3 class="title is-4">CRPS Scores and Monthly Forecasting</h3>
         
          <div class="columns is-centered is-vcentered">

            <div class="content has-text-justified">
              We also evaluated our model using CRPS (Continuous Ranked Probability Score) and Globaly monthly forecasting to forecast monthly averages of quantities, shown below. It can be seen our model can predict the weather quite well with predicted variance and bias outperform FCN in monthly forecasting. 
              <p align="center">
                  <img src="https://raw.githubusercontent.com/yogeshverma1998/ClimODE/master/static/images/crps_average.png" />
              </p>
              
            </div>
            
          </div>


         <h2 class="title is-3" id="ablations">Ablations</h2>

          <h3 class="title is-4" id="results-iwilds">Effect of emission model</h3>

          <div class="columns is-centered is-vcentered">
            <div class="column is-6 has-text-justified">
              <p>
                <!-- We train a classification model on the original spuriously correlated dataset with varying number of extra data points generated using different types of prompts. -->
                <!-- We measure the accuracy on a balanced set where waterbirds and landbirds appear on both land and water. -->
                The right plot shows model predictions <b>u(x,t)</b> of ground temperature (t2m) for a specific location while also including emission bias <span>&#181;</span> and variance <span>&#963;</span> . Remarkably, the model captures <font color="red"> diurnal variations and effectively estimates variance </font>. 
              </p>

              <p>
                <!-- We train a classification model on the original spuriously correlated dataset with varying number of extra data points generated using different types of prompts. -->
                <!-- We measure the accuracy on a balanced set where waterbirds and landbirds appear on both land and water. -->
                The bottom plot highlights bias and variance on a global scale. <font color="orange"> Positive bias is evident around the Pacific ocean </font> , corresponding to daytime, while a negative bias prevails around Europe and Africa, signifying nighttime. The  <font color="blue"> uncertainties indicate confidence </font>  in ocean estimation, with northern land regions being challenging.
              </p>
              
            </div>
            <div class="column is-1"></div>
            <div class="column is-5 has-text-centered">
              <img src="https://raw.githubusercontent.com/yogeshverma1998/ClimODE/master/static/images/mean_bias_showcase_final_v3.png" alt="Agreement Score" class="img-center">
            </div>
            
            
          </div>

        <p align="center">
                  <img src="https://raw.githubusercontent.com/yogeshverma1998/ClimODE/master/static/images/mean_std_tp_v1.png" />
        </p>
        

        <h3 class="title is-4">Effect of individual components</h3>
         
          <div class="columns is-centered is-vcentered">

            <div class="content has-text-justified">
              We analyze the contributions of various model components to its performance.The below plot delineates the impact of components: <font color="blue"> NODE</font> is a free-form second-order neural ODE, <font color="orange"> Adv</font> corresponds to the advection ODE form, <font color="green"> Att</font> adds the attention in addition to convolutions, and <font color="red"> ClimODE</font> adds also the emission component.
              <p align="center">
                  <img src="https://raw.githubusercontent.com/yogeshverma1998/ClimODE/master/static/images/ablation_final_v2.png" />
              </p>
              
            </div>
            
          </div>
        
        

          <h3 class="title is-4" id="results-iwilds">Additional results and analysis</h3>
          
          <div class="content has-text-justified">  
            We also have additional results on the following: <br>
            <p style="margin-left:20px;">
              <span>•</span> Results for <em>regional forecasting, longer-lead times</em> of various quantities and comparison to baselines <br>
              <span>•</span> Abaltion to check the mass-conserving property of the ODE-system.<br>
              <span>•</span> Correlations among the data variables.
            </p>
          </div>

      </div>
    </div>
  </div>
</section>



<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3" id="visualizations">Visualizations</h2>
        <h3 class="title is-3">Global Predictions</h3>
      <div class="content is-centered">
            Below is the global forecast video of various meteorological variables predicted by ClimODE. 
      <video poster="" width="100%" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/Slowed_climate_video_u10_comp.mp4"
        type="video/mp4" width="68">
      </video>
        <video poster="" width="100%" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/Slowed_climate_video_v10_comp.mp4"
        type="video/mp4" width="68">
      </video>
        <video poster="" width="100%" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/Slowed_climate_video_z_comp.mp4"
        type="video/mp4" width="68">
      </video>
        <video poster="" width="100%" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/Slowed_climate_video_t2m_comp.mp4"
        type="video/mp4" width="68">
      </video>
        v<video poster="" width="100%" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/Slowed_climate_video_t_comp.mp4"
        type="video/mp4" width="68">
      </video>
        </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3" id="visualizations" >Visualizations</h2>
        <h3 class="title is-3">Global Predictions</h3>
      <div class="content has-text-justified">
            Below is the global forecast video of various meteorological variables predicted by ClimODE. 
      </div>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="70%"> 
            <source src="static/videos/Slowed_climate_video_u10_comp.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="70%">
            <source src="static/videos/Slowed_climate_video_v10_comp.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="70%">
            <source src="static/videos/Slowed_climate_video_t_comp.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>








<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/fig1_v2_final.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <b>Climate as a quantity-preserving advection system</b>. A quantity (e.g., temperature) (a) is moved by a neural flow velocity (b), whose divergence is the flow's compressibility (c). The flow translates into state change by advection (d), which combines quantity's transport (e) and compression (f).
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/workflow_final_climate_v6.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
        <b>Whole prediction pipeline for ClimODE</b>
       </h2>
     </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->










<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{
verma2024climode,
title={Clim{ODE}: Climate Forecasting With Physics-informed Neural {ODE}s},
author={Yogesh Verma and Markus Heinonen and Vikas Garg},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=xuY33XhEGR}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
